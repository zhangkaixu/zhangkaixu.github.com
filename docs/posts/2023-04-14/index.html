<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>ChatGPT或成为人工智能CPU的“加法器” | 淺斟低唱</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="ChatGPT本身只是一个用于对话的语言模型，而且记忆有限。它本身并不能独立完成很复杂的任务。
但是，聊天的场景，也有它的优势之处：
使用自然语言作为输入输出，简直不是“可解释性”，而是“自解释性”。 输入输出非常灵活，没有所谓的“接口协议”的限制，它可以用来充当相当多的零部件。 现在的AutoGPT，就是反复调用ChatGPT，来完成更复杂的任务，从而形成一个更复杂的人工智能系统。
斯坦福的论文《generative agents interactive simulacra of human behavior》也给ChatGPT提供了类似内存的记忆模块。
回想日本上世纪搞的第五代计算机，这次似乎真的要搞出一个非冯诺依曼结构的“计算机”了。 那么像ChatGPT这种语言模型，会不会就成为如同现在CPU中“加法器”这样的最基础的运算单元呢？
虽然现在ChatGPT运算一次相当的缓慢且昂贵。 但谁敢说未来这玩意儿不会像集成电路一样的普及呢。 经济学家说不定会用GPU耗电量（占比）来衡量一个经济体的发达程度。">
    <meta name="generator" content="Hugo 0.111.3">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="ChatGPT或成为人工智能CPU的“加法器”" />
<meta property="og:description" content="ChatGPT本身只是一个用于对话的语言模型，而且记忆有限。它本身并不能独立完成很复杂的任务。
但是，聊天的场景，也有它的优势之处：
使用自然语言作为输入输出，简直不是“可解释性”，而是“自解释性”。 输入输出非常灵活，没有所谓的“接口协议”的限制，它可以用来充当相当多的零部件。 现在的AutoGPT，就是反复调用ChatGPT，来完成更复杂的任务，从而形成一个更复杂的人工智能系统。
斯坦福的论文《generative agents interactive simulacra of human behavior》也给ChatGPT提供了类似内存的记忆模块。
回想日本上世纪搞的第五代计算机，这次似乎真的要搞出一个非冯诺依曼结构的“计算机”了。 那么像ChatGPT这种语言模型，会不会就成为如同现在CPU中“加法器”这样的最基础的运算单元呢？
虽然现在ChatGPT运算一次相当的缓慢且昂贵。 但谁敢说未来这玩意儿不会像集成电路一样的普及呢。 经济学家说不定会用GPU耗电量（占比）来衡量一个经济体的发达程度。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zhangkaixu.github.io/posts/2023-04-14/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-14T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-04-14T00:00:00+00:00" />
<meta itemprop="name" content="ChatGPT或成为人工智能CPU的“加法器”">
<meta itemprop="description" content="ChatGPT本身只是一个用于对话的语言模型，而且记忆有限。它本身并不能独立完成很复杂的任务。
但是，聊天的场景，也有它的优势之处：
使用自然语言作为输入输出，简直不是“可解释性”，而是“自解释性”。 输入输出非常灵活，没有所谓的“接口协议”的限制，它可以用来充当相当多的零部件。 现在的AutoGPT，就是反复调用ChatGPT，来完成更复杂的任务，从而形成一个更复杂的人工智能系统。
斯坦福的论文《generative agents interactive simulacra of human behavior》也给ChatGPT提供了类似内存的记忆模块。
回想日本上世纪搞的第五代计算机，这次似乎真的要搞出一个非冯诺依曼结构的“计算机”了。 那么像ChatGPT这种语言模型，会不会就成为如同现在CPU中“加法器”这样的最基础的运算单元呢？
虽然现在ChatGPT运算一次相当的缓慢且昂贵。 但谁敢说未来这玩意儿不会像集成电路一样的普及呢。 经济学家说不定会用GPU耗电量（占比）来衡量一个经济体的发达程度。"><meta itemprop="datePublished" content="2023-04-14T00:00:00+00:00" />
<meta itemprop="dateModified" content="2023-04-14T00:00:00+00:00" />
<meta itemprop="wordCount" content="17">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="ChatGPT或成为人工智能CPU的“加法器”"/>
<meta name="twitter:description" content="ChatGPT本身只是一个用于对话的语言模型，而且记忆有限。它本身并不能独立完成很复杂的任务。
但是，聊天的场景，也有它的优势之处：
使用自然语言作为输入输出，简直不是“可解释性”，而是“自解释性”。 输入输出非常灵活，没有所谓的“接口协议”的限制，它可以用来充当相当多的零部件。 现在的AutoGPT，就是反复调用ChatGPT，来完成更复杂的任务，从而形成一个更复杂的人工智能系统。
斯坦福的论文《generative agents interactive simulacra of human behavior》也给ChatGPT提供了类似内存的记忆模块。
回想日本上世纪搞的第五代计算机，这次似乎真的要搞出一个非冯诺依曼结构的“计算机”了。 那么像ChatGPT这种语言模型，会不会就成为如同现在CPU中“加法器”这样的最基础的运算单元呢？
虽然现在ChatGPT运算一次相当的缓慢且昂贵。 但谁敢说未来这玩意儿不会像集成电路一样的普及呢。 经济学家说不定会用GPU耗电量（占比）来衡量一个经济体的发达程度。"/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        淺斟低唱
      
    </a>
    <div class="flex-l items-center">
      

      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1">ChatGPT或成为人工智能CPU的“加法器”</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2023-04-14T00:00:00Z">April 14, 2023</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>ChatGPT本身只是一个用于对话的语言模型，而且记忆有限。它本身并不能独立完成很复杂的任务。</p>
<p>但是，聊天的场景，也有它的优势之处：</p>
<ul>
<li>使用自然语言作为输入输出，简直不是“可解释性”，而是“自解释性”。</li>
<li>输入输出非常灵活，没有所谓的“接口协议”的限制，它可以用来充当相当多的零部件。</li>
</ul>
<p>现在的AutoGPT，就是反复调用ChatGPT，来完成更复杂的任务，从而形成一个更复杂的人工智能系统。</p>
<p>斯坦福的论文《generative agents interactive simulacra of human behavior》也给ChatGPT提供了类似内存的记忆模块。</p>
<p>回想日本上世纪搞的第五代计算机，这次似乎真的要搞出一个非冯诺依曼结构的“计算机”了。
那么像ChatGPT这种语言模型，会不会就成为如同现在CPU中“加法器”这样的最基础的运算单元呢？</p>
<p>虽然现在ChatGPT运算一次相当的缓慢且昂贵。
但谁敢说未来这玩意儿不会像集成电路一样的普及呢。
经济学家说不定会用GPU耗电量（占比）来衡量一个经济体的发达程度。</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://zhangkaixu.github.io/" >
    &copy;  淺斟低唱 2023 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
